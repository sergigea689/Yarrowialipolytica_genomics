#Script for the integration of CNV data and pangenome data
#Goal: creation of accessory genome matrix and pangenome matrix

# Load required libraries
library(readxl)
library(pheatmap)
library(RColorBrewer)

# -------------------------------
# 1. Load pangenome presence/absence matrix
# -------------------------------

# Read in the groups.tsv file generated by the pangenome pipeline
groups <- read.delim("groups.tsv", header = TRUE, sep = "\t")
matrix <- as.matrix(groups)
t <- t(matrix)
colnames(t) <- groups$name
t <- t[-1,]  # Remove first row (likely metadata)

# Clean up rownames (strain names)
rownames(t) <- gsub("\\.fasta$", "", rownames(t))
rownames(t) <- gsub("^([^.]*)\\.", "\\1-", rownames(t))

# -------------------------------
# 2. Remove diploid strains (outliers or redundant)
# -------------------------------

# Remove specific diploid strains by row and column
t <- t[!(rownames(t) %in% c("YL_9_concatenado", "YL_79_concatenado")), ]
t <- t[, !grepl("YL_9_concatenado|YL_79_concatenado", colnames(t))]

# -------------------------------
# 3. Load and align metadata
# -------------------------------

# Read in population metadata
popgen <- read_excel("update_manfinetreeposition.xlsx")
popgensub <- subset(popgen, popgen$treesamp %in% rownames(t))

# Check for name mismatches between metadata and matrix
setdiff(popgen$treesamp, rownames(t))

# Read in tree order for consistent plotting
trorder <- read.table("paperlabels.txt", header = FALSE, stringsAsFactors = FALSE)
trorder <- subset(trorder, trorder$V1 %in% popgensub$treesamp)

# Reorder metadata and matrix to match phylogenetic tree
popgensub <- popgensub[order(match(popgensub$treesamp, trorder$V1)), ]
popgensub$batch <- ifelse(grepl("^YL", popgensub$treesamp), "This study", "Others")
t <- t[order(match(rownames(t), popgensub$treesamp)), ]

# -------------------------------
# 4. Identify accessory genes enriched in a given batch (e.g., potential contamination)
# -------------------------------

# Convert to data.frame for analysis
t <- as.data.frame(t)

# Initialize container for significantly associated genes
significant_genes <- list()

# Test for enrichment of each gene across batch categories
for (gene in colnames(t)) {
  contingency_table <- table(t[[gene]], popgensub$batch)
  test_result <- if (min(contingency_table) < 5) {
    fisher.test(contingency_table)
  } else {
    chisq.test(contingency_table)
  }
  if (test_result$p.value < 0.05) {
    significant_genes[[gene]] <- test_result$p.value
  }
}

# -------------------------------
# 5. Create annotation object for heatmap
# -------------------------------

annotation <- as.data.frame(popgensub[, c("treesamp", "FinePop2")])
rownames(annotation) <- trimws(annotation$treesamp)
annotation <- annotation[, -1, drop = FALSE]
colnames(annotation) <- "FinePop2"

# -------------------------------
# 6. Define custom colors for populations
# -------------------------------

anno_col <- list(
  FinePop2 = c(
    "Eur1" = "#F29E6D", 
    "Eur2" = "#05A6A6", 
    "So-HC" = "#03738C", 
    "NoAm" = "#F23E2E", 
    "W29 clade" = "#152B59", 
    "Hyp" = "grey"
  ),
  dairy = c("Yes" = "lightblue", "No" = "darkgrey", "NA" = "white")
)

# Color scale for heatmap
palette_colors <- rev(brewer.pal(n = 10, name = "RdYlBu"))
breaks_intervals <- seq(from = -6, to = 4, length.out = 10)

# -------------------------------
# 7. Prepare heatmap matrix with only significantly associated genes
# -------------------------------

colnames(t) <- trimws(colnames(t))
tcont <- t[, colnames(t) %in% names(significant_genes)]
cont <- as.matrix(tcont)

# Convert matrix to numeric and transpose for plotting
t_numeric <- apply(cont, 2, as.numeric)
t_numeric <- t(t_numeric)
rownames(t_numeric) <- colnames(cont)
colnames(t_numeric) <- rownames(cont)

# -------------------------------
# 8. Plot accessory gene associations as heatmap
# -------------------------------

pdf("paper_batch associated_accessory_genes.pdf", width = 15, height = 10)
pheatmap(
  t_numeric,
  cluster_rows = TRUE,
  cluster_cols = FALSE,
  display_numbers = FALSE,
  breaks = breaks_intervals,
  main = "",
  format = "f",
  color = palette_colors,
  annotation_col = annotation,
  annotation_colors = anno_col,
  fontsize_row = 8,
  fontsize_col = 7,
  angle_col = 90,
  annotation_col_margin = 25,
  border_color = "snow3"
)
dev.off()

# -------------------------------------
# 9. Identify candidate contaminant genes exclusive to study batch
# -------------------------------------

# Transpose matrix so rows = strains, columns = genes
t_numeric <- t(t_numeric)

# Select strains from "This study" batch based on prefix "YL"
is_study_strain <- grepl("^YL", rownames(t_numeric))
group_study <- t_numeric[is_study_strain, ]
group_other <- t_numeric[!is_study_strain, ]

# Identify genes that appear in >30 "YL" strains but are absent elsewhere
# This suggests possible batch-specific contamination or misannotation
candidate_columns <- colnames(t_numeric)[
  colSums(group_study == 1) > 30 & colSums(group_other == 0) == nrow(group_other)
]

# Print genes satisfying those criteria
print(candidate_columns)

# -------------------------------------
# 10. Remove putative contaminant genes from the matrix
# -------------------------------------

# Remove the identified batch-specific genes from original matrix
t_clean <- t[, !(colnames(t) %in% candidate_columns)]

# Convert to numeric matrix for plotting
matrix_clean <- as.matrix(t_clean)
matrix_clean_t <- t(matrix_clean)
matrix_clean_numeric <- apply(matrix_clean_t, 2, as.numeric)
rownames(matrix_clean_numeric) <- rownames(matrix_clean_t)

# -------------------------------------
# 11. Visualize cleaned accessory gene matrix
# -------------------------------------

pheatmap(
  matrix_clean_numeric,
  cluster_rows = TRUE,
  cluster_cols = FALSE,
  display_numbers = FALSE,
  breaks = intervalos,  # Should be defined earlier in your script
  main = "",
  format = "f",
  color = mi_paleta,  # Should be defined earlier in your script
  annotation_col = anotacion,  # Should refer to previous population annotations
  annotation_colors = anno_col,
  fontsize_row = 8,
  fontsize_col = 7,
  angle_col = 90,
  annotation_col_margin = 25,
  border_color = "snow3"
)

# -------------------------------------
# 12. Load cleaned protein sequences for downstream analyses
# -------------------------------------

library(Biostrings)

# Load protein FASTA file containing only non-contaminant gene families
protein_sequences <- readAAStringSet("sequences.clean.prot.fa")

# -------------------------------------
# 13. Classify genes based on frequency: softcore, shell, cloud (based on gene loss CNV data)
# -------------------------------------

library(readxl)

# Load CNV data with categorical annotations (e.g. "loss")
cnv <- read_excel("D:/paper/CNV/wholegenes/allCNVscategorical.xlsx")

# Filter genes that show any evidence of loss across strains
loss <- cnv[apply(cnv, 1, function(row) any(grepl("loss", row, ignore.case = TRUE))), ]

# Compute the proportion of "loss" entries per gene
loss$loss_proportion <- apply(loss, 1, function(row) {
  sum(grepl("loss", row, ignore.case = TRUE)) / ncol(loss)
})

# Classify into pangenome categories based on presence/absence across strains
# - Cloud: lost in >95% of strains
# - Softcore: lost in <5%
# - Shell: between 5% and 95%
cloudloss <- loss[loss$loss_proportion > 0.95, ]
softcore <- loss[loss$loss_proportion < 0.05, ]
shell <- loss[loss$loss_proportion >= 0.05 & loss$loss_proportion <= 0.95, ]

# Remove temporary proportion column if not needed
cloudloss$loss_proportion <- NULL
softcore$loss_proportion <- NULL
shell$loss_proportion <- NULL

# -------------------------------------
# 14. Classify accessory genes identified by Pypan into softcore/shell/cloud
# -------------------------------------

# Work on filtered accessory gene matrix (clean)
cleant <- t(clean)
cleant <- as.data.frame(cleant)

# Compute proportion of absences (0s) per gene
cleant$loss_proportion <- apply(cleant, 1, function(row) {
  sum(grepl("0", row, ignore.case = TRUE)) / ncol(cleant)
})

# Classify genes based on absence proportion
cloudpan <- cleant[cleant$loss_proportion > 0.95, ]
softpan <- cleant[cleant$loss_proportion < 0.05, ]
shellpan <- cleant[cleant$loss_proportion >= 0.05 & cleant$loss_proportion <= 0.95, ]

# Remove temporary column
cloudpan$loss_proportion <- NULL
softpan$loss_proportion <- NULL
shellpan$loss_proportion <- NULL

# (Optional note)
# From 6309 core genes in reference, subtracting 126 soft losses, 57 shell, 1 cloud,
# leaves 6125 conserved core genes across population.

# -------------------------------------
# 15. Export protein sequences of cloud genes
# -------------------------------------

library(Biostrings)

# Extract protein sequences matching cloud gene identifiers
cloudseq <- protein_sequences[names(protein_sequences) %in% rownames(cloudpan)]

# Export unfiltered cloud protein sequences to FASTA
writeXStringSet(cloudseq, filepath = "cloudpan.fasta")

# -------------------------------------
# 16. Clean FASTA headers by removing unwanted annotations
# -------------------------------------

clean_protein_sequences <- function(aa_object) {
  cleaned_sequences <- sapply(aa_object, function(seq) {
    seq_char <- as.character(seq)
    clean_seq <- gsub("transcript:.*", "", seq_char)
    return(clean_seq)
  })
  
  cleaned_set <- AAStringSet(cleaned_sequences)
  names(cleaned_set) <- names(aa_object)
  return(cleaned_set)
}

# Apply cleaning function and export cleaned sequences
protein_sequences_cleaned <- clean_protein_sequences(cloudseq)
writeXStringSet(protein_sequences_cleaned, filepath = "cloudpan_cleaned_sequences.fasta")

# ------------------------------
# ACCESSORY GENE SET IDENTIFICATION AND VISUALIZATION
# ------------------------------

# STEP 1. Run this part in the terminal (not in R):
# Build a BLAST protein database from Saccharomycetales proteins
# makeblastdb -in saccharomycetales_proteins.fasta -dbtype prot -out saccharomycetales_db

# Run BLASTP to search cloudpan protein sequences against the Saccharomycetales protein database
# blastp -query cloudpan_cleaned_sequences.fasta -db saccharomycetales_db \
#        -out cloudpanSacc.txt -evalue 1e-4 -outfmt 6 -num_threads 8 -max_target_seqs 4
# This will produce a BLAST output file named 'cloudpanSacc.txt'

# ------------------------------
# STEP 2. Load and filter BLAST hits in R
# ------------------------------

# Load BLAST results (tab-separated format, no header)
blast_results <- read.table("cloudpanSacc2.txt", header = FALSE, sep = "\t", stringsAsFactors = FALSE)

# Extract unique query sequence identifiers (column 1 of BLAST output)
blast_identifiers <- unique(blast_results$V1)

# Load the Biostrings package to handle FASTA sequences
library(Biostrings)

# Read the input FASTA file with cloudpan protein sequences
fasta_sequences <- readAAStringSet("cloudpan_cleaned_sequences.fasta")

# Filter only sequences with at least one BLAST hit
filtered_sequencescloud <- fasta_sequences[names(fasta_sequences) %in% blast_identifiers]

# Save the filtered sequences to a new FASTA file
writeXStringSet(filtered_sequencescloud, "fungi_cloud_sequences.fasta")

# ------------------------------
# STEP 3. Combine shell and filtered cloud sequences
# ------------------------------

# Filter shellpan sequences from the original protein dataset
shellseq <- protein_sequences[names(protein_sequences) %in% rownames(shellpan)]

# Write shell sequences to FASTA
writeXStringSet(shellseq, "shellpan.fasta")

# Concatenate shell and cloud sequences to form the accessory pangenome
accesorypan <- c(shellseq, filtered_sequencescloud)

# Clean up sequences (remove invalid characters or formatting)
accesorypanclean <- clean_protein_sequences(accesorypan)

# Save the cleaned accessory pangenome sequences to FASTA
writeXStringSet(accesorypanclean, "accesory_pangenome.fasta")

# ------------------------------
# STEP 4. Build accessory gene presence/absence matrix
# ------------------------------

library(dplyr)

# Subset cloudpan matrix to retain only rows with BLAST-validated genes
filtcloudseq <- subset(cloudpan, rownames(cloudpan) %in% blast_identifiers)

# Combine filtered cloud genes and shellpan genes into one matrix
accesorymat <- rbind(filtcloudseq, shellpan)

# Convert matrix values to numeric for downstream analysis
accesorymatnum <- apply(accesorymat, 2, as.numeric)
rownames(accesorymatnum) <- rownames(accesorymat)

# Count the number of strains where each gene is present (value == 1)
row_ones <- rowSums(accesorymatnum == 1)

# Filter to retain only genes present in at least 5 strains
filtered_matrix <- accesorymatnum[row_ones >= 5, ]

# ------------------------------
# STEP 5. Visualize filtered accessory matrix as heatmap
# ------------------------------

# Output the heatmap to PDF
pdf("paper_shellgenome.pdf", width = 15, height = 10)

# Generate heatmap using pheatmap
pheatmap(filtered_matrix,
         cluster_rows = TRUE,               # Cluster genes
         cluster_cols = FALSE,              # Keep strain order fixed
         show_rownames = FALSE,             # Hide gene names
         show_colnames = FALSE,             # Hide strain names
         display_numbers = FALSE,           # Don't show matrix values
         breaks = intervalos,               # Custom color breakpoints
         color = mi_paleta,                 # Custom color palette
         annotation_col = anotacion,        # Metadata annotations for columns
         annotation_colors = anno_col,      # Colors for metadata
         fontsize_row = 8,                  # Font size for gene labels
         fontsize_col = 7,                  # Font size for strain labels
         angle_col = 90,                    # Rotate strain labels
         annotation_col_margin = 25,        # Margin for annotations
         border_color = "snow3"             # Border color for tiles
)

# Close the PDF device
dev.off()

# ----------------------------------------------
# Step 6: Integrate with gene loss information to build whole accesory matrix
# ----------------------------------------------


# Transpose the accessory gene numeric matrix
accesorymatnum_t <- t(accesorymatnum)


# Generate matrices for all non-core basal genes losses

# Cloud losses: transpose and reformat
clloss <- t(cloudloss)
# Use first row as column names
new_header <- as.character(clloss[1, ])  
clloss <- clloss[-1, ]  # Remove the first row (now header)
clloss <- as.data.frame(clloss)
colnames(clloss) <- new_header  # Assign new column names

# Shell losses: transpose and reformat
shloss <- t(shell)
new_header <- as.character(shloss[1, ])  
shloss <- shloss[-1, ]  
shloss <- as.data.frame(shloss)
colnames(shloss) <- new_header

# Soft losses: transpose and reformat
soloss <- t(softcore)
new_header <- as.character(soloss[1, ])  
soloss <- soloss[-1, ]  
soloss <- as.data.frame(soloss)
colnames(soloss) <- new_header

# Combine all losses into one data frame
losspan <- cbind(clloss, shloss, soloss)

# Check if there are any NA values in the combined matrix
any(is.na(losspan))


# Replace categorical values in 'losspan' with numeric codes:
# "no-cnv" -> 1, "loss" -> 0, "gain" -> 1, "inconclusive" -> 1
# Others remain as numeric if possible
library(dplyr)
losspan <- losspan %>%
  mutate(across(everything(), ~ case_when(
    . == "no-cnv" ~ 1,
    . == "loss" ~ 0,
    . == "gain" ~ 1,
    . == "inconclusive" ~ 1,
    TRUE ~ as.numeric(.)
  )))

# Additional conversion to numeric to catch any leftover strings
losspan[] <- lapply(losspan, function(x) {
  x <- ifelse(x == "no-cnv", 1,
              ifelse(x == "loss", 0,
                     ifelse(x == "gain", 1,
                            ifelse(x == "inconclusive", 1, x))))
  as.numeric(x)
})

# Prepare softpan matrix: transpose and convert to data frame
sopan <- t(softpan)
sopan <- as.data.frame(sopan)


# Ordering and subsetting to align matrices by row names

# Find rownames in accessory matrix but not in losspan
diff <- setdiff(rownames(accesorymatnum_t), rownames(losspan))

# Keep only rows common to both accesorymatnum_t and losspan
losspan <- subset(losspan, rownames(losspan) %in% rownames(accesorymatnum_t))
accesorymatnum_t <- subset(accesorymatnum_t, rownames(accesorymatnum_t) %in% rownames(losspan))

# Order losspan rows to match accesorymatnum_t row order
losspan <- losspan[order(match(rownames(losspan), rownames(accesorymatnum_t))),]

# Filter and order softpan to match accesorymatnum_t rows
sopan <- subset(sopan, rownames(sopan) %in% rownames(accesorymatnum_t))
sopan <- sopan[order(match(rownames(sopan), rownames(accesorymatnum_t))),]

# Combine accessory matrix, softpan, and loss pan matrices side by side
pangenomecomplete <- cbind(accesorymatnum_t, sopan, losspan)

# Ensure all values are numeric
pangenomecomplete <- as.data.frame(lapply(pangenomecomplete, as.numeric))

# Assign rownames back
rownames(pangenomecomplete) <- rownames(accesorymatnum_t)



#Saving
library(openxlsx)
pangenomecompletesave <- pangenomecomplete
pangenomecompletesave$identifier <- rownames(pangenomecompletesave)
write.xlsx(pangenomecompletesave, "nonbasalpangenomecomplete.xlsx")

shellcloudsave <- as.data.frame(accesorymatnum_t)
shellcloudsave$strain <- rownames(shellcloudsave)

# ------------------------------------------------
# Adding core genome to the matrix
# ------------------------------------------------

#### LOAD THE TSV FILE = Annotation file from the reference genome

tsv_data <- read.table("C:/Users/USUARIO/Desktop/genomes/ref/anno_yali0.tsv",
                       header = TRUE, sep = "\t", quote = "", fill = TRUE, comment.char = "")

# Check the number of unique gene names
length(unique(tsv_data$Name))
# --------------------------------
# Step 1: Fix the TSV file if necessary
# --------------------------------

# Ensure essential columns exist; create them if missing
required_cols <- c("Contig", "Start", "End", "Name", "Note")
for (col in required_cols) {
  if (!col %in% colnames(tsv_data)) {
    tsv_data[[col]] <- NA
  }
}

# Identify rows where 'Start' is empty or NA and correct these rows
rows_to_fix <- tsv_data$Start == "" | is.na(tsv_data$Start)

# Split the 'Nº.gen.chr' column by whitespace for rows that need fixing,
# keeping up to the first 6 splits
split_data <- strsplit(tsv_data$Nº.gen.chr[rows_to_fix], " +", perl = TRUE)

# Extract individual columns from the split data
Contig <- sapply(split_data, function(x) if (length(x) >= 2) x[2] else NA)
Start <- sapply(split_data, function(x) if (length(x) >= 3) as.integer(x[3]) else NA)
End <- sapply(split_data, function(x) if (length(x) >= 4) as.integer(x[4]) else NA)
Kind <- sapply(split_data, function(x) if (length(x) >= 5) x[5] else NA)
Name <- sapply(split_data, function(x) if (length(x) >= 6) x[6] else NA)

# Combine any remaining parts as a single string for the 'Note' column
Note <- sapply(split_data, function(x) {
  if (length(x) > 6) paste(x[7:length(x)], collapse = " ") else NA
})

# Retrieve the original row numbers from the first element
OriginalRowNumber <- sapply(split_data, function(x) if (length(x) >= 1) as.integer(x[1]) else NA)

# Update the original dataframe with fixed values for the selected rows
tsv_data$Contig[rows_to_fix] <- Contig
tsv_data$Start[rows_to_fix] <- Start
tsv_data$End[rows_to_fix] <- End
tsv_data$Kind[rows_to_fix] <- Kind
tsv_data$Name[rows_to_fix] <- Name
tsv_data$Note[rows_to_fix] <- Note
tsv_data$Nº.gen.chr[rows_to_fix] <- OriginalRowNumber

# Display the first rows of the cleaned dataset
print(head(tsv_data))

# Filter the dataset to keep only CDS features
tsv_data <- subset(tsv_data, Kind == "CDS")

# Convert 'Start' and 'End' columns to numeric
tsv_data$Start <- as.numeric(tsv_data$Start)
tsv_data$End <- as.numeric(tsv_data$End)

# Replace missing 'End' values with 'Start' + 1000 (approximate gene length)
tsv_data$End <- ifelse(is.na(tsv_data$End), tsv_data$Start + 1000, tsv_data$End)

# Remove entries annotated as pseudogenes, no similarity, or None in 'Note'
tsv_data <- tsv_data[!grepl("pseudogene", tsv_data$Note, ignore.case = TRUE), ]
tsv_data <- tsv_data[!grepl("no similarity", tsv_data$Note, ignore.case = TRUE), ]
tsv_data <- tsv_data[!grepl("None", tsv_data$Note, ignore.case = TRUE), ]

# ---------------------------------
#  Step 2: Integrate core genes
# ---------------------------------

# Extract unique gene names and filter out those ending with 't' or 'r'
core_genes_all <- unique(as.character(tsv_data$Name))
core_genes_filtered <- core_genes_all[!grepl("t$", core_genes_all)]
core_genes_filtered <- core_genes_filtered[!grepl("r$", core_genes_filtered)]

# Identify core genes missing from the pangenome matrix
core_genes <- core_genes_filtered
existing_genes <- colnames(pangenomecomplete)
missing_genes <- setdiff(core_genes, existing_genes)

# Add missing core genes to the pangenome matrix with default value 1
pangenome_matrix <- pangenomecomplete
for (gene in missing_genes) {
  pangenome_matrix[[gene]] <- 1
}

# Check the updated pangenome matrix
head(pangenome_matrix)

# Load necessary packages for downstream analysis
install.packages("micropan")
library(vegan)
library(micropan)

# Filter out contamination by removing columns containing "ERR5235159_"
pangenome_matrix_clean <- pangenome_matrix[, !grepl("ERR5235159_", colnames(pangenome_matrix))]

# Export the cleaned pangenome matrix to an Excel file
write.xlsx(pangenome_matrix_clean, "pangenome_matrix_clean_whole.xlsx")
